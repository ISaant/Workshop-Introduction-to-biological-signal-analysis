{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc3864d",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:3rem;color:orange;\">Classification Algorithms</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79229dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import time \n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "import pandas as pd\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import metrics as Metrics\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38d2ca",
   "metadata": {},
   "source": [
    "## KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(df,K):\n",
    "    \n",
    "    #Centroids=df[np.random.choice(df.shape[0], size=K, replace=False)]\n",
    "    Centroids=5.5*np.random.randn(3,2)\n",
    "    y_pred=np.empty(len(df))\n",
    "    fig = plt.figure(figsize = (10, 7))\n",
    "    scat0=plt.scatter(df[:,0],df[:,1], color = \"green\", linewidth=4)\n",
    "    scat3=plt.scatter(Centroids[:,0],Centroids[:,1], color=\"magenta\",linewidth=4)\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "    plt.pause(1)\n",
    "    for h in range(10):\n",
    "        cont=0;\n",
    "        for i in df:\n",
    "            Dist=np.zeros(K)\n",
    "            for j in range(K):\n",
    "                Dist[j]+=np.sqrt (((i[0]-Centroids[j][0])**2)+(i[1]-Centroids[j][1])**2)\n",
    "            y_pred[cont]=np.argmin(Dist)\n",
    "            cont+=1\n",
    "            \n",
    "            \n",
    "            for j in range(K):\n",
    "                CenData=df[y_pred==j]\n",
    "                Centroids[j]=[np.mean(CenData[:,0]),np.mean(CenData[:,1])]\n",
    "        \n",
    "        scat0.remove()\n",
    "        scat3.remove()\n",
    "        if 'scat1' in locals():\n",
    "            scat1.remove()   \n",
    "            scat2.remove()\n",
    "        scat0=plt.scatter(df[y_pred==0,0],df[y_pred==0,1], color = \"green\", linewidth=4)\n",
    "        scat1=plt.scatter(df[y_pred==1,0],df[y_pred==1,1], color = \"orange\",linewidth=4)\n",
    "        scat2=plt.scatter(df[y_pred==2,0],df[y_pred==2,1], color = \"blue\",linewidth=4)\n",
    "        scat3=plt.scatter(Centroids[:,0],Centroids[:,1], color=\"magenta\",linewidth=4)\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "        plt.pause(1)\n",
    "\n",
    "        \n",
    "        plt.title('Kmeans Iteration= '+str(h))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "n_samples = 1500\n",
    "random_state = 170\n",
    "X, y = make_blobs(n_samples=n_samples, random_state=random_state,centers=10,cluster_std=1)\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "Kmeans(X,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % label)\n",
    "    \n",
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337405d",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "n_samples = 1500\n",
    "random_state = 170\n",
    "#X, y = make_blobs(n_samples=n_samples, random_state=random_state,centers=5,cluster_std=[1.0,3.0,2.0,.5,5])\n",
    "X, y = make_blobs(n_samples=n_samples, random_state=random_state,centers=5,cluster_std=3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KNN(df,targets):\n",
    "\n",
    "    random_state = np.random.RandomState(0)\n",
    "    x_train, x_test, train_labels, test_labels = train_test_split(df, targets,\n",
    "                                                            test_size=.2,\n",
    "                                                            random_state=random_state)\n",
    "    y_pred=np.empty(len(x_test))\n",
    "    clss=len(np.unique(train_labels))\n",
    "    \n",
    "    Time=[]\n",
    "    f1Score=[]\n",
    "    for h in np.arange(1,round(len(x_train)/(clss+5))): # Choose number of neighbours\n",
    "        #clear_output(wait=True)\n",
    "        print(h)\n",
    "        start = time.time()\n",
    "        cont=0\n",
    "        for i in x_test:\n",
    "            Dist=np.zeros(clss)\n",
    "            for j in range(clss):\n",
    "                neigh=x_train[train_labels==j]\n",
    "                Nneigh=(neigh[np.random.choice(neigh.shape[0], \n",
    "                        size=h, replace=False)])\n",
    "                for k in range(h):\n",
    "                    Dist[j]+=np.sqrt (((i[0]-Nneigh[k][0])**2)+(i[1]-Nneigh[k][1])**2)\n",
    "            y_pred[cont]=np.argmin(Dist)\n",
    "            cont+=1\n",
    "        end = time.time()\n",
    "        \n",
    "        Time.append(end-start)\n",
    "        f1Score.append(f1_score(test_labels,y_pred,average='macro'))\n",
    "    matrix = tf.math.confusion_matrix(test_labels, y_pred)\n",
    "    print(matrix)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(1,len(x_train)/(clss+5)),Time)\n",
    "    plt.plot(np.arange(1,len(x_train)/(clss+5)),f1Score)\n",
    "    plt.legend(['Time [s]','f1_score'])\n",
    "    plt.xlabel('Time, f1_score')\n",
    "    plt.ylabel('K neighbors')\n",
    "    \n",
    "plt.figure(figsize=(12, 12))\n",
    "n_samples = 1500\n",
    "random_state = 170\n",
    "X, y = make_blobs(n_samples=n_samples, random_state=random_state,centers=5,cluster_std=3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "KNN(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 8))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % label)\n",
    "    \n",
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.2, shuffle=False)\n",
    "\n",
    "n_neighbors=15\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "# knn.fit(X, y)\n",
    "\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d7f6c",
   "metadata": {},
   "source": [
    "## ANN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TF(cm):\n",
    "    tp=np.zeros(cm.shape[0])\n",
    "    tn=np.zeros(cm.shape[0])\n",
    "    fp=np.zeros(cm.shape[0])\n",
    "    fn=np.zeros(cm.shape[0])\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[0]):\n",
    "            if i==j:\n",
    "                tp[i]=cm[i,j]\n",
    "            if i!=j:\n",
    "                fn[i]+=cm[i][j]        \n",
    "                fp[i]+=cm[j][i]\n",
    "                \n",
    "    for k in range(cm.shape[0]):\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[0]):\n",
    "                if i!=k and j!=k:\n",
    "                    tn[k]+=cm[i][j]\n",
    "                    \n",
    "    return tp,tn,fp,fn\n",
    "\n",
    "def NNplot(X,y):\n",
    "    \n",
    "    random_state = np.random.RandomState(0)\n",
    "    X_train, X_test, train_labels, test_labels = train_test_split(X,y,\n",
    "                                                            test_size=.2,\n",
    "                                                            random_state=random_state)\n",
    "    clss=len(np.unique(train_labels))\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    network.add(layers.Dense(64, activation='relu'))\n",
    "    network.add(layers.Dense(32, activation='relu'))\n",
    "    network.add(layers.Dense(clss, activation='softmax'))\n",
    "    \n",
    "    network.compile(optimizer=Adam(lr=.001),\n",
    "                  loss=losses.binary_crossentropy,\n",
    "                  metrics=[metrics.binary_accuracy,metrics.Precision(), \n",
    "                            metrics.Recall(),\n",
    "                            metrics.TrueNegatives(),\n",
    "                            metrics.FalsePositives()])\n",
    "    \n",
    "    y_train = to_categorical(train_labels)\n",
    "    history=network.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        validation_split=0.1,\n",
    "        verbose=0)\n",
    "    \n",
    "    y_test_base = np.reshape(np.array([test_labels],dtype=np.int).T,(test_labels.shape[0]))\n",
    "    y_test = to_categorical(test_labels)\n",
    "    \n",
    "    y_pred = network.predict(X_test)\n",
    "    y_pred2=np.argmax(y_pred,axis=1)\n",
    "    matrix = tf.math.confusion_matrix(y_test_base, y_pred2)\n",
    "    to_hist=np.max(y_pred,axis=1)\n",
    "    \n",
    "    labels=list(np.arange(0,clss).astype(str))\n",
    "    fig, axs = plt.subplots(1,2,figsize=(18,10))\n",
    "    cm = Metrics.confusion_matrix(y_test_base, y_pred2)\n",
    "    disp=Metrics.ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "    disp.plot(ax=axs[0])\n",
    "    axs[0].set_title('NN Confusion Matrix')\n",
    "    \n",
    "    report=Metrics.classification_report(y_test_base, y_pred2)\n",
    "    precisions, recall, f1_score, _ = Metrics.precision_recall_fscore_support(y_test_base, y_pred2)\n",
    "    results = network.evaluate(X_test, y_test, batch_size=128)\n",
    "    loss, acc, precision_new, recall_new, TN, FP=results\n",
    "    tp,tn,fp,fn=TF(cm)\n",
    "    Speci=tn/(tn+fp)\n",
    "    \n",
    "    Class=np.repeat(labels,4)\n",
    "    MetricStruct=(np.vstack((precisions,recall,f1_score,Speci)).T).reshape(clss*4,)\n",
    "    \n",
    "    dataFrame2=pd.DataFrame({'Class':Class,'Percentage':MetricStruct,\n",
    "                             'Metric':['Precision: '+str(round(precision_new,3)),\n",
    "                                       'Recall: '+str(round(recall_new,3)),\n",
    "                                       'F1_Score: '+str(round(acc,3)),\n",
    "                                       'Specificity: ' +str(round(TN/(TN+FP),3))]*clss})\n",
    "    sns.barplot(x=\"Class\", y='Percentage', hue=\"Metric\", data=dataFrame2,palette=\"Blues_d\", ax=axs[1])\n",
    "    axs[1].set_title('Presicion, Recall and F1_Score per class')\n",
    "    axs[1].set_ylim(.8,1)\n",
    "    \n",
    "plt.figure(figsize=(12, 12))\n",
    "n_samples = 1500\n",
    "random_state = 170\n",
    "X, y = make_blobs(n_samples=n_samples, random_state=random_state,centers=5,cluster_std=1)\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "NNplot(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 8))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % label)\n",
    "    \n",
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "NNplot(data,digits.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40731e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
